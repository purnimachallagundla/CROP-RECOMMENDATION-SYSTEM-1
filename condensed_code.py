# -*- coding: utf-8 -*-
"""condensed code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/157qQJkEdu2R9c7UDz3DDSCJbIwC70Jsp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv('/content/Crop_recommendation.csv')
df = crop.copy()


if "yield" not in df.columns:
    np.random.seed(42)
    df["yield"] = (
        0.3*df["N"] + 0.2*df["P"] + 0.1*df["K"] +
        0.5*df["rainfall"] + 0.2*df["temperature"] -
        0.4*(df["ph"]-6.5)**2 + np.random.normal(0, 5, size=len(df))
    )

X = df.drop(columns=["yield", "label"], errors='ignore')
y = df["yield"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


num_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=["object"]).columns.tolist()
numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])
categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_transformer, num_features),
    ("cat", categorical_transformer, cat_features)
])


rf_pipeline = Pipeline([
    ("pre", preprocessor),
    ("model", RandomForestRegressor(n_estimators=200, random_state=42))
])

rf_pipeline.fit(X_train, y_train)
y_pred = rf_pipeline.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)


mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\nModel Performance:")
print(f"MAE  : {mae:.2f}")
print(f"RMSE : {rmse:.2f}")
print(f"RÂ²   : {r2:.2f}")


if 'label' in df.columns and not pd.api.types.is_numeric_dtype(df['label']):
    plt.figure(figsize=(8,6))
    sns.heatmap(df.drop('label', axis=1).corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap (excluding label)")
else:
    plt.figure(figsize=(8,6))
    sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap")
plt.show()

# True vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
plt.xlabel("True Yield")
plt.ylabel("Predicted Yield")
plt.title("True vs Predicted - Random Forest")
plt.show()

# Residuals Histogram
residuals = y_test - y_pred
plt.figure(figsize=(6,4))
plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
plt.title("Residuals Histogram")
plt.xlabel("Residuals")
plt.show()

# Feature Importances
rf_model = rf_pipeline.named_steps["model"]
cat_names = rf_pipeline.named_steps["pre"].named_transformers_["cat"].named_steps["onehot"].get_feature_names_out(cat_features) if cat_features else []
feature_names = num_features + list(cat_names)

importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)
plt.figure(figsize=(8,6))
importances.head(10).plot(kind="barh", color="green")
plt.title("Top 10 Feature Importances")
plt.xlabel("Importance")
plt.gca().invert_yaxis()
plt.show()