# -*- coding: utf-8 -*-
"""CONDENSED CODE WITH SYNTACTICAL CHANGES.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fHJy_Skl2oProd0Q5HzTFGifqwh4acKa
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

#Load the crop recommendation dataset

def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        return df
    except Exception as e:
        print(f"Failed to load data: {e}")
        return None

#Ensure the 'yield' column exists, generating it if necessary

def ensure_yield_column(df):
    if "yield" not in df.columns:
        np.random.seed(42)
        df["yield"] = (
            0.3 * df["N"] + 0.2 * df["P"] + 0.1 * df["K"] +
            0.5 * df["rainfall"] + 0.2 * df["temperature"] -
            0.4 * (df["ph"]-6.5)**2 + np.random.normal(0, 5, size=len(df))
        )
    return df

# Prepare data for modeling

def prepare_data(df):
    X = df.drop(columns=["yield","label"], errors='ignore')
    y = df["yield"]
    return X, y

# Split data into training and testing sets

def split_data(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test

#Define preprocessing steps for numeric and categorical features

def create_preprocessor(num_features, cat_features):
    numeric_transformer = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])

    categorical_transformer = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])

    preprocessor = ColumnTransformer([
        ("num", numeric_transformer, num_features),
        ("cat", categorical_transformer, cat_features)
    ])

    return preprocessor

#Train a random forest regressor model

def train_model(preprocessor, X_train, y_train):
    rf_pipeline = Pipeline([
        ("pre", preprocessor),
        ("model", RandomForestRegressor(n_estimators=200, random_state=42))
    ])

    rf_pipeline.fit(X_train, y_train)
    return rf_pipeline

#Evaluate model performance

def evaluate_model(rf_pipeline, X_test, y_test):
    y_pred = rf_pipeline.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    return mae, rmse, r2

#Plot correlation heatmap

def plot_correlation_heatmap(df):
    if 'label' in df.columns and not pd.api.types.is_numeric_dtype(df['label']):
        plt.figure(figsize=(8,6))
        sns.heatmap(df.drop('label', axis=1).corr(), annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Correlation Heatmap (excluding label)")
    else:
        plt.figure(figsize=(8,6))
        sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Correlation Heatmap")
    plt.show()

#Plot true vs predicted yields

def plot_true_vs_predicted(y_test, y_pred):
    plt.figure(figsize=(6,6))
    plt.scatter(y_test, y_pred, alpha=0.6)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
    plt.xlabel("True Yield")
    plt.ylabel("Predicted Yield")
    plt.title("True vs Predicted - Random Forest")
    plt.show()

#Plot residuals histogram

def plot_residuals_histogram(y_test, y_pred):
    residuals = y_test - y_pred
    plt.figure(figsize=(6,4))
    plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
    plt.title("Residuals Histogram")
    plt.xlabel("Residuals")
    plt.show()

#Plot feature importances

def plot_feature_importances(rf_model, num_features, cat_features, preprocessor):
    cat_names = preprocessor.named_transformers_["cat"].named_steps["onehot"].get_feature_names_out(cat_features) if cat_features else []
    feature_names = num_features + list(cat_names)

    importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)
    plt.figure(figsize=(8,6))
    importances.head(10).plot(kind="barh", color="green")
    plt.title("Top 10 Feature Importances")
    plt.xlabel("Importance")
    plt.gca().invert_yaxis()
    plt.show()

#Main function to execute the analysis

def main():
    file_path = '/content/Crop_recommendation.csv'
    df = load_data(file_path)
    if df is None:
        return

    # Make sure 'yield' column exists
    df = ensure_yield_column(df)

    X, y = prepare_data(df)
    X_train, X_test, y_train, y_test = split_data(X, y)

    num_features = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_features = X.select_dtypes(include=["object"]).columns.tolist()

    preprocessor = create_preprocessor(num_features, cat_features)
    rf_pipeline = train_model(preprocessor, X_train, y_train)

    mae, rmse, r2 = evaluate_model(rf_pipeline, X_test, y_test)

    print("\nModel Performance:")
    print(f"MAE : {mae:.2f}")
    print(f"RMSE : {rmse:.2f}")
    print(f"RÂ² : {r2:.2f}")

    plot_correlation_heatmap(df)
    plot_true_vs_predicted(y_test, rf_pipeline.predict(X_test))
    plot_residuals_histogram(y_test, rf_pipeline.predict(X_test))

    rf_model = rf_pipeline.named_steps["model"]
    plot_feature_importances(rf_model, num_features, cat_features, preprocessor)

if __name__ == "__main__":
    main()