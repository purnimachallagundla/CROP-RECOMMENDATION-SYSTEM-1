# -*- coding: utf-8 -*-
"""CROP RECOMMENDATION SYSTEM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lZ3vJGr9kisJRF71qXxqKzyD32GIcDBx

**IMPORT LIBRARIES**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""**LOAD DATASET**"""

df = pd.read_csv('/content/Crop_recommendation.csv')
df = crop.copy()

"""**CREATION OF SYNTHETIC YIELD**"""

if "yield" not in df.columns:
    np.random.seed(42)
    df["yield"] = (
        0.3*df["N"] + 0.2*df["P"] + 0.1*df["K"] +
        0.5*df["rainfall"] + 0.2*df["temperature"] -
        0.4*(df["ph"]-6.5)**2 + np.random.normal(0, 5, size=len(df))
    )

"""FEATURES AND TARGET"""

X = df.drop(columns=["yield", "label"], errors='ignore')
y = df["yield"] # 'yield' is the target for regression

"""**SPLIT TRAIN/TEST**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**PREPROCESSING**"""

num_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=["object"]).columns.tolist() # Check for any remaining object type columns

numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])
categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_transformer, num_features),
    ("cat", categorical_transformer, cat_features)
])

"""**RANDOM FOREST MODEL**"""

rf_pipeline = Pipeline([
    ("pre", preprocessor),
    ("model", RandomForestRegressor(n_estimators=200, random_state=42))
])

rf_pipeline.fit(X_train, y_train)
y_pred = rf_pipeline.predict(X_test)

"""**EVALUATION**"""

mae = mean_absolute_error(y_test, y_pred)

"""**Calculation of  RMSE by taking the square root of the MSE**"""

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\nModel Performance:")
print(f"MAE  : {mae:.2f}")
print(f"RMSE : {rmse:.2f}")
print(f"R²   : {r2:.2f}")

"""**GRAPHS**"""

if 'label' in df.columns and not pd.api.types.is_numeric_dtype(df['label']):
    plt.figure(figsize=(8,6))
    sns.heatmap(df.drop('label', axis=1).corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap (excluding label)")
else:
    plt.figure(figsize=(8,6))
    sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap")
plt.show()

# True vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
plt.xlabel("True Yield")
plt.ylabel("Predicted Yield")
plt.title("True vs Predicted - Random Forest")
plt.show()

# Residuals Histogram
residuals = y_test - y_pred
plt.figure(figsize=(6,4))
plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
plt.title("Residuals Histogram")
plt.xlabel("Residuals")
plt.show()

# Feature Importances
rf_model = rf_pipeline.named_steps["model"]
cat_names = rf_pipeline.named_steps["pre"].named_transformers_["cat"].named_steps["onehot"].get_feature_names_out(cat_features) if cat_features else []
feature_names = num_features + list(cat_names)

importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)
plt.figure(figsize=(8,6))
importances.head(10).plot(kind="barh", color="green")
plt.title("Top 10 Feature Importances")
plt.xlabel("Importance")
plt.gca().invert_yaxis()
plt.show()

"""**FINAL CODE**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


df = pd.read_csv('/content/Crop_recommendation.csv')
df = crop.copy()


if "yield" not in df.columns:
    np.random.seed(42)
    df["yield"] = (
        0.3*df["N"] + 0.2*df["P"] + 0.1*df["K"] +
        0.5*df["rainfall"] + 0.2*df["temperature"] -
        0.4*(df["ph"]-6.5)**2 + np.random.normal(0, 5, size=len(df))
    )

X = df.drop(columns=["yield", "label"], errors='ignore')
y = df["yield"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


num_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=["object"]).columns.tolist()
numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])
categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_transformer, num_features),
    ("cat", categorical_transformer, cat_features)
])


rf_pipeline = Pipeline([
    ("pre", preprocessor),
    ("model", RandomForestRegressor(n_estimators=200, random_state=42))
])

rf_pipeline.fit(X_train, y_train)
y_pred = rf_pipeline.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)


mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\nModel Performance:")
print(f"MAE  : {mae:.2f}")
print(f"RMSE : {rmse:.2f}")
print(f"R²   : {r2:.2f}")


if 'label' in df.columns and not pd.api.types.is_numeric_dtype(df['label']):
    plt.figure(figsize=(8,6))
    sns.heatmap(df.drop('label', axis=1).corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap (excluding label)")
else:
    plt.figure(figsize=(8,6))
    sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
    plt.title("Correlation Heatmap")
plt.show()

# True vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
plt.xlabel("True Yield")
plt.ylabel("Predicted Yield")
plt.title("True vs Predicted - Random Forest")
plt.show()

# Residuals Histogram
residuals = y_test - y_pred
plt.figure(figsize=(6,4))
plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
plt.title("Residuals Histogram")
plt.xlabel("Residuals")
plt.show()

# Feature Importances
rf_model = rf_pipeline.named_steps["model"]
cat_names = rf_pipeline.named_steps["pre"].named_transformers_["cat"].named_steps["onehot"].get_feature_names_out(cat_features) if cat_features else []
feature_names = num_features + list(cat_names)

importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)
plt.figure(figsize=(8,6))
importances.head(10).plot(kind="barh", color="green")
plt.title("Top 10 Feature Importances")
plt.xlabel("Importance")
plt.gca().invert_yaxis()
plt.show()

"""**FINAL CODE WITH SYNTACTICAL MODIFICATIONS**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

#Load the crop recommendation dataset

def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        return df
    except Exception as e:
        print(f"Failed to load data: {e}")
        return None

#Ensure the 'yield' column exists, generating it if necessary

def ensure_yield_column(df):
    if "yield" not in df.columns:
        np.random.seed(42)
        df["yield"] = (
            0.3 * df["N"] + 0.2 * df["P"] + 0.1 * df["K"] +
            0.5 * df["rainfall"] + 0.2 * df["temperature"] -
            0.4 * (df["ph"]-6.5)**2 + np.random.normal(0, 5, size=len(df))
        )
    return df

# Prepare data for modeling

def prepare_data(df):
    X = df.drop(columns=["yield","label"], errors='ignore')
    y = df["yield"]
    return X, y

# Split data into training and testing sets

def split_data(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test

#Define preprocessing steps for numeric and categorical features

def create_preprocessor(num_features, cat_features):
    numeric_transformer = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])

    categorical_transformer = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])

    preprocessor = ColumnTransformer([
        ("num", numeric_transformer, num_features),
        ("cat", categorical_transformer, cat_features)
    ])

    return preprocessor

#Train a random forest regressor model

def train_model(preprocessor, X_train, y_train):
    rf_pipeline = Pipeline([
        ("pre", preprocessor),
        ("model", RandomForestRegressor(n_estimators=200, random_state=42))
    ])

    rf_pipeline.fit(X_train, y_train)
    return rf_pipeline

#Evaluate model performance

def evaluate_model(rf_pipeline, X_test, y_test):
    y_pred = rf_pipeline.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    return mae, rmse, r2

#Plot correlation heatmap

def plot_correlation_heatmap(df):
    if 'label' in df.columns and not pd.api.types.is_numeric_dtype(df['label']):
        plt.figure(figsize=(8,6))
        sns.heatmap(df.drop('label', axis=1).corr(), annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Correlation Heatmap (excluding label)")
    else:
        plt.figure(figsize=(8,6))
        sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Correlation Heatmap")
    plt.show()

#Plot true vs predicted yields

def plot_true_vs_predicted(y_test, y_pred):
    plt.figure(figsize=(6,6))
    plt.scatter(y_test, y_pred, alpha=0.6)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
    plt.xlabel("True Yield")
    plt.ylabel("Predicted Yield")
    plt.title("True vs Predicted - Random Forest")
    plt.show()

#Plot residuals histogram

def plot_residuals_histogram(y_test, y_pred):
    residuals = y_test - y_pred
    plt.figure(figsize=(6,4))
    plt.hist(residuals, bins=30, color="skyblue", edgecolor="black")
    plt.title("Residuals Histogram")
    plt.xlabel("Residuals")
    plt.show()

#Plot feature importances

def plot_feature_importances(rf_model, num_features, cat_features, preprocessor):
    cat_names = preprocessor.named_transformers_["cat"].named_steps["onehot"].get_feature_names_out(cat_features) if cat_features else []
    feature_names = num_features + list(cat_names)

    importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)
    plt.figure(figsize=(8,6))
    importances.head(10).plot(kind="barh", color="green")
    plt.title("Top 10 Feature Importances")
    plt.xlabel("Importance")
    plt.gca().invert_yaxis()
    plt.show()

#Main function to execute the analysis

def main():
    file_path = '/content/Crop_recommendation.csv'
    df = load_data(file_path)
    if df is None:
        return

    # Make sure 'yield' column exists
    df = ensure_yield_column(df)

    X, y = prepare_data(df)
    X_train, X_test, y_train, y_test = split_data(X, y)

    num_features = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_features = X.select_dtypes(include=["object"]).columns.tolist()

    preprocessor = create_preprocessor(num_features, cat_features)
    rf_pipeline = train_model(preprocessor, X_train, y_train)

    mae, rmse, r2 = evaluate_model(rf_pipeline, X_test, y_test)

    print("\nModel Performance:")
    print(f"MAE : {mae:.2f}")
    print(f"RMSE : {rmse:.2f}")
    print(f"R² : {r2:.2f}")

    plot_correlation_heatmap(df)
    plot_true_vs_predicted(y_test, rf_pipeline.predict(X_test))
    plot_residuals_histogram(y_test, rf_pipeline.predict(X_test))

    rf_model = rf_pipeline.named_steps["model"]
    plot_feature_importances(rf_model, num_features, cat_features, preprocessor)

if __name__ == "__main__":
    main()